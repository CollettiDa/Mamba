{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "622fa918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'my_mambanet' from '/home/collettida/myprojects/ExploringMamba/code/my_mambanet.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import mamba_ssm\n",
    "import networks.mamba_sys as mamba_sys\n",
    "import torch\n",
    "import torch as tc\n",
    "import my_mambanet\n",
    "import importlib\n",
    "import torch.nn as nn\n",
    "\n",
    "importlib.reload(my_mambanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5de3de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---final upsample expand_first---\n",
      "Input shape to MambaUNet: torch.Size([16, 30, 24, 24])\n",
      "After Patch Embedding: torch.Size([16, 8, 8, 96])\n",
      "After layer: torch.Size([16, 4, 4, 192])\n",
      "After layer: torch.Size([16, 2, 2, 384])\n",
      "After layer: torch.Size([16, 1, 1, 768])\n",
      "After layer: torch.Size([16, 1, 1, 768])\n",
      "After norm: torch.Size([16, 1, 1, 768])\n",
      "Decoder layer index: 0 Input shape: torch.Size([16, 1, 1, 768])\n",
      "After decoder layer: torch.Size([16, 2, 2, 384])\n",
      "Decoder layer index: 1 Input shape: torch.Size([16, 2, 2, 384])\n",
      "After decoder layer: torch.Size([16, 4, 4, 192])\n",
      "Decoder layer index: 2 Input shape: torch.Size([16, 4, 4, 192])\n",
      "After decoder layer: torch.Size([16, 8, 8, 96])\n",
      "Decoder layer index: 3 Input shape: torch.Size([16, 8, 8, 96])\n",
      "After decoder layer: torch.Size([16, 8, 8, 96])\n",
      "After norm up: torch.Size([16, 8, 8, 96])\n",
      "Before final upsample: torch.Size([16, 8, 8, 96])\n",
      "After final upsample: torch.Size([16, 2, 24, 24])\n",
      "torch.Size([16, 2, 21, 21])\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "# model = mamba_sys.().to('cuda')\n",
    "model = my_mambanet.MambaUNet(patch_size=3,in_chans=30, num_classes=2).to('cuda')\n",
    "inp = torch.randn(16,30,21,21).cuda()\n",
    "# int = torch.randn(16,1,21,21).cuda()\n",
    "out = model(inp)\n",
    "l = loss(out, torch.randn_like(out))\n",
    "l.backward()\n",
    "print(out.shape)\n",
    "print(\"done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9c0780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedVideo(nn.Module):\n",
    "    \"\"\" Video to Patch Embedding\n",
    "    Args:\n",
    "        img_size (int): Frame size.  Default: 21\n",
    "        in_chans (int): Number of input image channels. Default: 3\n",
    "        n_frames (int): Number of frames. Default: 8\n",
    "        patch_size (int): Patch token size. Default: 3\n",
    "        stride (int): Stride of the patch embedding. Default: None\n",
    "        embed_dim (int): Number of linear projection output channels. Default: 96.\n",
    "        norm_layer (nn.Module, optional): Normalization layer. Default: None\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size=21, n_frames=8, patch_size=3, \n",
    "                 stride=None, in_chans=2, embed_dim=96, groups=1, \n",
    "                 norm_layer=None, **kwargs):\n",
    "        super().__init__()\n",
    "        if isinstance(patch_size, int):\n",
    "            patch_size = (patch_size, patch_size)\n",
    "        if stride is None:\n",
    "            stride = patch_size\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, \n",
    "                              embed_dim, \n",
    "                              kernel_size=patch_size,\n",
    "                              stride=patch_size,\n",
    "                              groups=groups)\n",
    "        if norm_layer is not None:\n",
    "            self.norm = norm_layer(embed_dim)\n",
    "        else:\n",
    "            self.norm = None \n",
    "        \n",
    "    def forward(self, x: tc.Tensor):\n",
    "        \"\"\" Forward function.\n",
    "        Args:\n",
    "            x: (tc.Tensor) Input video of shape (B, T, C, H, W)\n",
    "        Returns:\n",
    "            tc.Tensor: Patch embedded video of shape (B, H', W', embed_dim)\n",
    "        \"\"\"\n",
    "        B, T, C, H, W = x.shape\n",
    "         \n",
    "        for t in range(T):\n",
    "            x_t = x[:, t, :, :, :]  # (B, C, H, W)\n",
    "            x_t = self.proj(x_t)  # (B, embed_dim, H', W')\n",
    "            if t == 0:\n",
    "                print(x_t.shape)\n",
    "                x_out = x_t.unsqueeze(1)  # (B, 1, embed_dim, H', W')\n",
    "                print(x_out.shape)\n",
    "            else:\n",
    "                x_out = tc.cat((x_out, x_t.unsqueeze(1)), dim=1)  # (B, T, embed_dim, H', W')\n",
    "        \n",
    "\n",
    "        if self.norm is not None:\n",
    "            x_out = self.norm(x_out)\n",
    "        \n",
    "        return x_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2960eebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 96, 7, 7])\n",
      "torch.Size([16, 1, 96, 7, 7])\n",
      "torch.Size([16, 15, 96, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "pev = PatchEmbedVideo(image_size=21, n_frames=15, patch_size=3, in_chans=2, embed_dim=96).to('cuda')\n",
    "\n",
    "inp = torch.randn(16,15,2,21,21).cuda()\n",
    "out = pev(inp)\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edde0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from einops import rearrange, repeat \n",
    "import torch.nn.functional as F\n",
    "from mamba_ssm.ops.selective_scan_interface import selective_scan_fn\n",
    "\n",
    "class SS2D(nn.Module):\n",
    "    r\"\"\" Mamba SSM layer for 2D inputs.\n",
    "    2D-Selective-Scan for Vision Data (SS2D)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model,\n",
    "        d_state=16,\n",
    "        d_conv=3,\n",
    "        expand=2,\n",
    "        dt_rank=\"auto\",\n",
    "        dt_min=0.001,\n",
    "        dt_max=0.1,\n",
    "        dt_init=\"random\",\n",
    "        dt_scale=1.0,\n",
    "        dt_init_floor=1e-4,\n",
    "        dropout=0.0,\n",
    "        conv_bias=True,\n",
    "        bias=False,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_state = d_state\n",
    "        self.d_conv = d_conv \n",
    "        self.expand = expand\n",
    "        self.d_inner = int(self.d_model * self.expand)\n",
    "        self.dt_rank = math.ceil(self.d_model / 16) if dt_rank == \"auto\" else dt_rank\n",
    "\n",
    "        # Input projection to xz\n",
    "        self.in_proj = nn.Linear(self.d_model,\n",
    "                                 self.d_inner*2,\n",
    "                                 bias=bias,\n",
    "                                 **factory_kwargs)\n",
    "        # DW conv\n",
    "        self.conv2d = nn.Conv2d(\n",
    "            in_channels=self.d_inner,\n",
    "            out_channels=self.d_inner,\n",
    "            groups=self.d_inner,\n",
    "            bias=conv_bias,\n",
    "            kernel_size=d_conv,\n",
    "            padding=(d_conv-1) // 2,\n",
    "            **factory_kwargs,\n",
    "        )\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "        # 4 projections for [dt, B, C] calculation\n",
    "        self.x_proj = (\n",
    "            nn.Linear(self.d_inner, (self.dt_rank+self.d_state*2), bias=False, **factory_kwargs),\n",
    "            nn.Linear(self.d_inner, (self.dt_rank+self.d_state*2), bias=False, **factory_kwargs),\n",
    "            nn.Linear(self.d_inner, (self.dt_rank+self.d_state*2), bias=False, **factory_kwargs),\n",
    "            nn.Linear(self.d_inner, (self.dt_rank+self.d_state*2), bias=False, **factory_kwargs),\n",
    "        )\n",
    "        self.x_proj_weight = nn.Parameter(tc.stack([t.weight for t in self.x_proj], dim=0)) # (K=4, N, inner)\n",
    "        del self.x_proj\n",
    "\n",
    "        \n",
    "        self.dt_projs = (\n",
    "            self.dt_init(self.dt_rank, self.d_inner, dt_scale, dt_init, dt_min, dt_max, dt_init_floor, **factory_kwargs),\n",
    "            self.dt_init(self.dt_rank, self.d_inner, dt_scale, dt_init, dt_min, dt_max, dt_init_floor, **factory_kwargs),\n",
    "            self.dt_init(self.dt_rank, self.d_inner, dt_scale, dt_init, dt_min, dt_max, dt_init_floor, **factory_kwargs),\n",
    "            self.dt_init(self.dt_rank, self.d_inner, dt_scale, dt_init, dt_min, dt_max, dt_init_floor, **factory_kwargs),\n",
    "        )\n",
    "        self.dt_projs_weight = nn.Parameter(tc.stack([t.weight for t in self.dt_projs], dim=0)) # (K=4, inner, rank)\n",
    "        self.dt_projs_bias = nn.Parameter(tc.stack([t.bias for t in self.dt_projs], dim=0)) # (K=4, inner)\n",
    "        del self.dt_projs\n",
    "\n",
    "        self.A_logs = self.A_log_init(self.d_state, self.d_inner, copies=4, merge=True) # (K=4, D, N)\n",
    "        self.Ds = self.D_init(self.d_inner, copies=4, merge=True) # (K=4, D, N)\n",
    "\n",
    "        self.forward_core = self.forward_corev0\n",
    "        \n",
    "        self.out_norm = nn.LayerNorm(self.d_inner)\n",
    "        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=bias, **factory_kwargs)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0. else None\n",
    "\n",
    "    @staticmethod\n",
    "    def dt_init(dt_rank, d_inner, dt_scale=1.0, dt_init=\"random\", \n",
    "                dt_min=0.001, dt_max=0.1, dt_init_floor=1e-4, **factory_kwargs):\n",
    "        dt_proj = nn.Linear(dt_rank, d_inner, bias=True, **factory_kwargs)\n",
    "\n",
    "        # Initialize special dt projection to preserve variance at initialization\n",
    "        dt_init_std = dt_rank**-0.5 * dt_scale\n",
    "        if dt_init == \"constant\":\n",
    "            nn.init.constant_(dt_proj.weight, dt_init_std)\n",
    "        elif dt_init == \"random\":\n",
    "            nn.init.uniform_(dt_proj.weight, -dt_init_std, dt_init_std)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        # Initialize dt bias so that F.softplus(dt_bias) is between dt_min and dt_max\n",
    "        dt = tc.exp(\n",
    "            tc.rand(d_inner, **factory_kwargs) * (math.log(dt_max) - math.log(dt_min))\n",
    "            + math.log(dt_min)).clamp(min=dt_init_floor)\n",
    "        # Inverse of softplus: https://github.com/pytorch/pytorch/issues/72759\n",
    "        inv_dt = dt + tc.log(-tc.expm1(-dt))\n",
    "        with tc.no_grad():\n",
    "            dt_proj.bias.copy_(inv_dt)\n",
    "        # Our initialization would set all Linear.bias to zero, need to mark this one as _no_reinit\n",
    "        dt_proj.bias._no_reinit = True\n",
    "        \n",
    "        return dt_proj\n",
    "\n",
    "    @staticmethod\n",
    "    def A_log_init(d_state, d_inner, copies=1, device=None, merge=True):\n",
    "        # S4D real initialization\n",
    "        A = repeat(\n",
    "            tc.arange(1, d_state + 1, dtype=tc.float32, device=device),\n",
    "            \"n -> d n\",\n",
    "            d=d_inner,\n",
    "        ).contiguous()\n",
    "        A_log = tc.log(A)  # Keep A_log in fp32\n",
    "        if copies > 1:\n",
    "            A_log = repeat(A_log, \"d n -> r d n\", r=copies)\n",
    "            if merge:\n",
    "                A_log = A_log.flatten(0, 1)\n",
    "        A_log = nn.Parameter(A_log)\n",
    "        A_log._no_weight_decay = True\n",
    "        return A_log\n",
    "\n",
    "    @staticmethod\n",
    "    def D_init(d_inner, copies=1, device=None, merge=True):\n",
    "        # D \"skip\" parameter\n",
    "        D = tc.ones(d_inner, device=device)\n",
    "        if copies > 1:\n",
    "            D = repeat(D, \"n1 -> r n1\", r=copies)\n",
    "            if merge:\n",
    "                D = D.flatten(0, 1)\n",
    "        D = nn.Parameter(D)  # Keep in fp32\n",
    "        D._no_weight_decay = True\n",
    "        return D\n",
    "\n",
    "    def forward_corev0(self, x: tc.Tensor):\n",
    "        r\"\"\" Core forward function for SS2D.\n",
    "        Performs SS on 4 sequence obtained by inspecting the input 2D feature map\n",
    "        along different directions: (H→W), (W→H), (H→W flipped), (W→H flipped).\n",
    "        \"\"\"\n",
    "        self.selective_scan = selective_scan_fn\n",
    "\n",
    "        B, C, H, W = x.shape\n",
    "        L = H*W # sequence length = N of tokens\n",
    "        K = 4  # number of projections\n",
    "\n",
    "        x_hwwh = tc.stack([x.view(B, -1, L), tc.transpose(x, dim0=2, dim1=3).contiguous().view(B, -1, L)], dim=1).view(B, 2, -1, L)\n",
    "        xs = tc.cat([x_hwwh, tc.flip(x_hwwh, dims=[-1])], dim=1) # (b, k, d, l)\n",
    "\n",
    "        x_bdl = tc.einsum(\"b k d l, k c d -> b k c l\", xs.view(B, K, -1, L), self.x_proj_weight)\n",
    "        dts, Bs, Cs = tc.split(x_bdl, [self.dt_rank, self.d_state, self.d_state], dim=2)  \n",
    "        dts = tc.einsum(\"b k r l, k d r -> b k d l\", dts.view(B,K,-1,L), self.dt_projs_weight)\n",
    "\n",
    "        xs = xs.view(B, -1, L)\n",
    "        dts = dts.contiguous().float().view(B, -1, L)\n",
    "        Bs = Bs.float().view(B, K, -1, L) # (b, k, d_state, l)\n",
    "        Cs = Cs.float().view(B, K, -1, L) # (b, k, d_state, l)\n",
    "        \n",
    "        Ds = self.Ds.float().view(-1)\n",
    "        As = -tc.exp(self.A_logs.float()).view(-1, self.d_state) \n",
    "        dt_projs_bias = self.dt_projs_bias.float().view(-1)\n",
    "\n",
    "        out_y = self.selective_scan(\n",
    "            xs, dts,\n",
    "            As, Bs, Cs, Ds, z=None,\n",
    "            delta_bias=dt_projs_bias,\n",
    "            delta_softplus=True,\n",
    "            return_last_state=False,\n",
    "        ).view(B, K, -1, L)\n",
    "        assert out_y.dtype == tc.float\n",
    "\n",
    "        inv_y = tc.flip(out_y[:, 2:4], dims=[-1]).view(B, 2, -1, L)\n",
    "        wh_y =  tc.transpose(out_y[:, 1].view(B, -1, H, W), dim0=2, dim1=3).contiguous().view(B, -1, L)\n",
    "        invwh_y = tc.transpose(inv_y[:, 1].view(B, -1, H, W), dim0=2, dim1=3).contiguous().view(B, -1, L)        \n",
    "        y = out_y[:, 0] + inv_y[:, 0] + wh_y + invwh_y\n",
    "        y = tc.transpose(y, dim0=1, dim1=2).contiguous().view(B, H, W, -1)\n",
    "        y = self.out_norm(y).to(x.dtype)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def forward(self, x: tc.Tensor, **kwargs):\n",
    "        B, H, W, C = x.shape\n",
    "        print(f\"x input shape: {x.shape}\")\n",
    "        xz = self.in_proj(x)\n",
    "        print(f\"xz shape: {xz.shape}\")\n",
    "        x, z = xz.chunk(2, dim=-1) # each: (B, H, W, d_inner)\n",
    "        print(f\"x shape after chunk: {x.shape}\")\n",
    "        print(f\"z shape after chunk: {z.shape}\")\n",
    "        \n",
    "        x = x.permute(0, 3, 1, 2).contiguous()\n",
    "        x = self.conv2d(x)\n",
    "        x = self.act(x)\n",
    "        y = self.forward_core(x)\n",
    "        y = y * F.silu(z)\n",
    "        out = self.out_proj(y)\n",
    "        if self.dropout is not None:\n",
    "            out = self.dropout(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "850c837a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x input shape: torch.Size([16, 21, 21, 96])\n",
      "xz shape: torch.Size([16, 21, 21, 384])\n",
      "x shape after chunk: torch.Size([16, 21, 21, 192])\n",
      "z shape after chunk: torch.Size([16, 21, 21, 192])\n",
      "torch.Size([16, 21, 21, 96])\n"
     ]
    }
   ],
   "source": [
    "ss2d = SS2D(d_model=96, d_state=16, d_conv=3).to('cuda')\n",
    "inp = torch.randn(16,21,21,96).cuda()\n",
    "out = ss2d(inp)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051af29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
